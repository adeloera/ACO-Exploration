---
title: "ACO Dataset Builder"
author: "Andres de Loera-Brust"
date: "April 26, 2019"
output: html_document
---

The purpose of this rmd file is to build ad save all the datasets I will use in in the Shiny app I create to explore the Medicare Shared Savings Program (MSSP). In the code I import, clean, and manipulate the data on Accountable Care Organization (ACO) beneficiaries at the county level. The data here comes from the Center for Medicare and Medicaid Services (CMS). There are four datasets available, one for each year from 2014 to 2017, where the unit of observation is a unique ACO-county combination. I use these four files, and a US county map shapefile from the Census Bureau, to create a dataset where the unit of observation is a county year with data on the ACO beneficiary population for each county in the continental united states and each year from 2014 to 2017. I also read in a different dataset on MSSP participating ACOs in each year from 2014 to 2017, do some manipulation of them, and then append them to create a dataset of ACO years. 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#I begin as always by loading in the libraries I will use. 

library(janitor)
library(sf)
library(fs)
library(readxl)
library(lubridate)
library(tidyverse)
library(gganimate)

```


```{r importation, echo = FALSE, message = FALSE ,warning = FALSE, cache = TRUE}
#This code chunk imports the some of the data I will be using. 
#First off is the data on the beneficiaries assigned to Medicare Shared Savings Program (MSSP) Acountable care Organizations (ACOs). 
  #The unit of observation is the ACO-county: each entry is data on an ACO's beneficiary population in a certain county. This data can be collapsed to either the ACO level or the county level, depending on project needs.
  #This data is made available by the Center for Medicare and Medicaid Services (CMS).
  #I will use this data to create a dynamic map showing the Medicare beneficiary population assigned to ACOs over time. 
  #So far I have only created the map included below.
#Other graphics will be made using the public use files on each ACO organizations, found at the link below: https://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/SSPACO/index.html

#Now to download the data: I start with 2017. 
  #First I download the zip file directly from the CMS website.

download.file(url = "https://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/SSPACO/Downloads/ACOSSPCOUNTYASSIGNEDPUF2017.zip",
              dest = "aco_county_2017puf.zip",
              mode = "wb")

  #Second I untar the zip file to get the dictionary and spreadsheet available in my workspace.

untar("aco_county_2017puf.zip")

  #Third I read the csv file into an r object, which for now I keep roughly in the original format.

aco_county_benes_2017 <- read_csv("ACO.SSP.COUNTY.ASSIGNED.PUF.2017.csv") %>%
  
    #I call clean names for ease of use.
  
  clean_names() %>%
  
    #I create a numeric total beneficiaries variable.
  
  mutate(total_benes = as.numeric(tot_ab),
         total_benes = replace_na(total_benes, 0)) %>%
  
    #Finally I select just the variables I will want later.
  
  select(year, aco_id, state_name, county_name, state_id, county_id, total_benes)


#I repeat the process for 2016: 
  #First I download the zip file directly from the CMS website.

download.file(url = "https://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/SSPACO/Downloads/ACOSSPCOUNTYASSIGNEDPUF2016.zip",
              dest = "aco_county_2016puf.zip",
              mode = "wb")

  #Second I untar the zip file to get the dictionary and spreadsheet available in my workspace.

untar("aco_county_2016puf.zip")

  #Third I read the csv file into an r object, which for now I keep roughly in the original format.

aco_county_benes_2016 <- read_csv("ACO.SSP.COUNTY.ASSIGNED.PUF.2016.csv") %>%
  
    #I call clean names for ease of use.
  
  clean_names() %>%
  
    #I create a numeric total beneficiaries variable.
  
  mutate(total_benes = as.numeric(tot_ab),
         total_benes = replace_na(total_benes, 0)) %>%
  
    #Finally I select just the variables I will want later.
  
  select(year, aco_id, state_name, county_name, state_id, county_id, total_benes)


#I repeat the same process for 2015: 
  #First I download the zip file directly from the CMS website.

download.file(url = "https://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/SSPACO/Downloads/ACOSSPCOUNTYASSIGNEDPUF2015.zip",
              dest = "aco_county_2015puf.zip",
              mode = "wb")

  #Second I untar the zip file to get the dictionary and spreadsheet available in my workspace.

untar("aco_county_2015puf.zip")

  #Third I read the csv file into an r object, which for now I keep roughly in the original format.

aco_county_benes_2015 <- read_csv("ACO.SSP.COUNTY.ASSIGNED.PUF.2015.csv") %>%
  
    #I call clean names for ease of use.
  
  clean_names() %>%
  
    #I create a numeric total beneficiaries variable.
  
  mutate(total_benes = as.numeric(tot_ab),
         total_benes = replace_na(total_benes, 0)) %>%
  
    #Finally I select just the variables I will want later.
  
  select(year, aco_id, state_name, county_name, state_id, county_id, total_benes)


#I now repeat the process one last time for 2014: 
  #First I download the zip file directly from the CMS website.

download.file(url = "https://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/SSPACO/Downloads/ACOSSPCOUNTYASSIGNEDPUF2014.zip",
              dest = "aco_county_2014puf.zip",
              mode = "wb")

  #Second I untar the zip file to get the dictionary and spreadsheet available in my workspace.

untar("aco_county_2014puf.zip")

  #Third I read the csv file into an r object, which for now I keep roughly in the original format.

aco_county_benes_2014 <- read_csv("ACO.SSP.COUNTY.ASSIGNED.PUF.2014.csv") %>%
  
    #I call clean names for ease of use.
  
  clean_names() %>%
  
    #I create a numeric total beneficiaries variable.
  
  mutate(total_benes = as.numeric(tot_ab),
         total_benes = replace_na(total_benes, 0)) %>%
  
    #Finally I select just the variables I will want later.
  
  select(year, aco_id, state_name, county_name, state_id, county_id, total_benes)


#Now I import a US map shapefile to be able to do mapping

#This comes from the census bureau, which makes map files of the US like the one I will use publicly available.
#I start by downloading a zip file with several file versions of a US county level map.

download.file(url = "https://www2.census.gov/geo/tiger/GENZ2016/shp/cb_2016_us_county_500k.zip",
              dest = "county_shapefile.zip",
              mode = "wb")

#I untar the zip file.

untar("county_shapefile.zip")

#And finally I save the shapefile I want as an r object. 

county_map <- read_sf("cb_2016_us_county_500k.shp") %>%
  clean_names()


#Next I import some county level data about the Medicare Program as a whole, 
#which I will use to compare with the MSSP.

#First I download the zip file with all the data.

download.file(url = "https://downloads.cms.gov/files/State-County-All-Table-2017.zip",
              dest = "medicare_spending.zip",
              mode = "wb")

#I then untar it, which yields "State County All Table 2017.xlsx" which has a lot of data for each year. 
#The data for each year is kept as a seperate sheet in this spreadsheet. 

untar("medicare_spending.zip")

#Now I read in and lightly clean the data for each year. 
#Starting with 2017...

county_medicare_2017 <- read_excel("State County All Table 2017.xlsx", 
    sheet = "State_county 2017", skip = 1) %>%
  
  #I call clean names to ease of use.
  
  clean_names() %>%
  
  #I select just the variables I will use
  
  select(state, county, state_and_county_fips_code, beneficiaries_with_part_a_and_part_b, ffs_beneficiaries, ma_beneficiaries, ma_participation_rate, average_age, total_actual_costs, actual_per_capita_costs) %>%
  
  #I remove the observations that are not counties or are not in the contiguous US.
  
  filter(!is.na(state_and_county_fips_code), state != "AK", state != "HI") %>%
  
  #I then set variables to be numerics with zeroes as appropriate. 
  
  mutate(beneficiaries_with_part_a_and_part_b = as.numeric(beneficiaries_with_part_a_and_part_b),
         beneficiaries_with_part_a_and_part_b = replace_na(beneficiaries_with_part_a_and_part_b, 0),
         ma_beneficiaries = as.numeric(ma_beneficiaries),
         ma_beneficiaries = replace_na(ma_beneficiaries, 0),
         average_age = as.numeric(average_age),
         average_age = replace_na(average_age, 0),
         actual_per_capita_costs = as.numeric(actual_per_capita_costs),
         actual_per_capita_costs = replace_na(actual_per_capita_costs, 0),
         total_actual_costs = as.numeric(total_actual_costs),
         total_actual_costs = replace_na(total_actual_costs, 0),
         ffs_beneficiaries = as.numeric(ffs_beneficiaries),
         ffs_beneficiaries = replace_na(ffs_beneficiaries, 0)) %>%
  
  #Lastly I mutate the state variable from codes to names
  
  mutate(state = state.name[match(state,state.abb)])

#I repeat the process for the preceding years too. 
#Now 2016...

county_medicare_2016 <- read_excel("State County All Table 2017.xlsx", 
    sheet = "State_county 2016", skip = 1) %>%
  
  #I call clean names to ease of use.
  
  clean_names() %>%
  
  #I select just the variables I will use
  
  select(state, county, state_and_county_fips_code, beneficiaries_with_part_a_and_part_b, ffs_beneficiaries, ma_beneficiaries, ma_participation_rate, average_age, total_actual_costs, actual_per_capita_costs) %>%
  
  #I remove the observations that are not counties or are not in the contiguous US.
  
  filter(!is.na(state_and_county_fips_code), state != "AK", state != "HI") %>%
  
  #I then set variables to be numerics with zeroes as appropriate. 
  
  mutate(beneficiaries_with_part_a_and_part_b = as.numeric(beneficiaries_with_part_a_and_part_b),
         beneficiaries_with_part_a_and_part_b = replace_na(beneficiaries_with_part_a_and_part_b, 0),
         ma_beneficiaries = as.numeric(ma_beneficiaries),
         ma_beneficiaries = replace_na(ma_beneficiaries, 0),
         average_age = as.numeric(average_age),
         average_age = replace_na(average_age, 0),
         actual_per_capita_costs = as.numeric(actual_per_capita_costs),
         actual_per_capita_costs = replace_na(actual_per_capita_costs, 0),
         total_actual_costs = as.numeric(total_actual_costs),
         total_actual_costs = replace_na(total_actual_costs, 0),
         ffs_beneficiaries = as.numeric(ffs_beneficiaries),
         ffs_beneficiaries = replace_na(ffs_beneficiaries, 0)) %>%
  
  #Lastly I mutate the state variable from codes to names
  
  mutate(state = state.name[match(state,state.abb)])

#Now for 2015:

county_medicare_2015 <- read_excel("State County All Table 2017.xlsx", 
    sheet = "State_county 2015", skip = 1) %>%
  
  #I call clean names to ease of use.
  
  clean_names() %>%
  
  #I select just the variables I will use
  
  select(state, county, state_and_county_fips_code, beneficiaries_with_part_a_and_part_b, ffs_beneficiaries, ma_beneficiaries, ma_participation_rate, average_age, total_actual_costs, actual_per_capita_costs) %>%
  
  #I remove the observations that are not counties or are not in the contiguous US.
  
  filter(!is.na(state_and_county_fips_code), state != "AK", state != "HI") %>%
  
  #I then set variables to be numerics with zeroes as appropriate. 
  
  mutate(beneficiaries_with_part_a_and_part_b = as.numeric(beneficiaries_with_part_a_and_part_b),
         beneficiaries_with_part_a_and_part_b = replace_na(beneficiaries_with_part_a_and_part_b, 0),
         ma_beneficiaries = as.numeric(ma_beneficiaries),
         ma_beneficiaries = replace_na(ma_beneficiaries, 0),
         average_age = as.numeric(average_age),
         average_age = replace_na(average_age, 0),
         actual_per_capita_costs = as.numeric(actual_per_capita_costs),
         actual_per_capita_costs = replace_na(actual_per_capita_costs, 0),
         total_actual_costs = as.numeric(total_actual_costs),
         total_actual_costs = replace_na(total_actual_costs, 0),
         ffs_beneficiaries = as.numeric(ffs_beneficiaries),
         ffs_beneficiaries = replace_na(ffs_beneficiaries, 0)) %>%
  
  #Lastly I mutate the state variable from codes to names
  
  mutate(state = state.name[match(state,state.abb)])

#And finally 2014:

county_medicare_2014 <- read_excel("State County All Table 2017.xlsx", 
    sheet = "State_county 2014", skip = 1) %>%
  
  #I call clean names to ease of use.
  
  clean_names() %>%
  
  #I select just the variables I will use
  
  select(state, county, state_and_county_fips_code, beneficiaries_with_part_a_and_part_b, ffs_beneficiaries, ma_beneficiaries, ma_participation_rate, average_age, total_actual_costs, actual_per_capita_costs) %>%
  
  #I remove the observations that are not counties or are not in the contiguous US.
  
  filter(!is.na(state_and_county_fips_code), state != "AK", state != "HI") %>%
  
  #I then set variables to be numerics with zeroes as appropriate. 
  
  mutate(beneficiaries_with_part_a_and_part_b = as.numeric(beneficiaries_with_part_a_and_part_b),
         beneficiaries_with_part_a_and_part_b = replace_na(beneficiaries_with_part_a_and_part_b, 0),
         ma_beneficiaries = as.numeric(ma_beneficiaries),
         ma_beneficiaries = replace_na(ma_beneficiaries, 0),
         average_age = as.numeric(average_age),
         average_age = replace_na(average_age, 0),
         actual_per_capita_costs = as.numeric(actual_per_capita_costs),
         actual_per_capita_costs = replace_na(actual_per_capita_costs, 0),
         total_actual_costs = as.numeric(total_actual_costs),
         total_actual_costs = replace_na(total_actual_costs, 0),
         ffs_beneficiaries = as.numeric(ffs_beneficiaries),
         ffs_beneficiaries = replace_na(ffs_beneficiaries, 0)) %>%
  
  #Lastly I mutate the state variable from codes to names
  
  mutate(state = state.name[match(state,state.abb)])


#Here I download the ACO level datasets with more detailed program paramenters 
#from the CMS website and perform some basic cleaning. 

#To create a length of service variable I will use four date variables I will create here.

date2017 <- as.Date("2018/01/01")
date2016 <- as.Date("2017/01/01")
date2015 <- as.Date("2016/01/01")
date2014 <- as.Date("2015/01/01")

#I begin with the 2017 dataset. 
#I read in the dataset from a url of CMS's data download site. I use col_names and deliberately set the format of some of the columns. 

aco_data_2017 <- read_csv("https://data.cms.gov/api/views/gk7c-vejx/rows.csv?accessType=DOWNLOAD",
                          col_names = TRUE,
                          cols(
                            .default = col_double(),
                            ACO_Num = col_character(),
                            ACO_Name = col_character(),
                            ACO_State = col_character(),
                            Agree_Type = col_character(),
                            Initial_Start_Date = col_character(),
                            Current_Start_Date = col_character(),
                            ACO18 = col_character(),
                            ACO19 = col_character(),
                            ACO20 = col_character(),
                            ACO42 = col_character(),
                            ACO40 = col_character(),
                            DM_Comp = col_character(),
                            ACO27 = col_character(),
                            ACO41 = col_character(),
                            ACO28 = col_character(),
                            ACO30 = col_character()
                          )) %>%
  
  #I call clean_names for ease of use later.
  
  clean_names() %>%
  
  #I also select just the variables that I may use in later analysis to have a more managable dataset. 
  
  select(aco_num, aco_name, aco_state, initial_start_date, n_ab, sav_rate, bnchmk_min_exp, gen_save_loss, earn_save_loss, qual_score, updated_bnchmk, a_btot_bnchmk, a_btot_exp, final_share_rate, per_capita_exp_total_py)%>%
  
  #Next I reformat the intital start time variable as a date and creating a "length of service" variable. 
  
  mutate(initial_start_date = as.Date(initial_start_date, format = "%m/%d/%Y"),
         service_length = date2017-initial_start_date,
         
  #Critically, I also add a year variable. 
  
         year = 2017) 

#Now for 2016: 
#I read in the dataset from a url of CMS's data download site. I use col_names and deliberately set the format of some of the columns. 

aco_data_2016 <- read_csv("https://data.cms.gov/api/views/3jk5-q6dr/rows.csv?accessType=DOWNLOAD",
                          col_names = TRUE,
                          cols(
                            .default = col_double(),
                            ACO_Num = col_character(),
                            ACO_Name = col_character(),
                            ACO_State = col_character(),
                            Agree_Type = col_character(),
                            Initial_Start_Date = col_character(),
                            Current_Start_Date = col_character(),
                            ACO18 = col_character(),
                            ACO19 = col_character(),
                            ACO20 = col_character(),
                            ACO42 = col_character(),
                            ACO40 = col_character(),
                            DM_Comp = col_character(),
                            ACO27 = col_character(),
                            ACO41 = col_character(),
                            ACO28 = col_character(),
                            ACO30 = col_character()
                          )) %>%
  
  #I call clean_names for ease of use later.
  
  clean_names() %>%
  
  #I also select just the variables that I may use in later analysis to have a more managable dataset. 
  
  select(aco_num, aco_name, aco_state, initial_start_date, n_ab, sav_rate, bnchmk_min_exp, gen_save_loss, earn_save_loss, qual_score, updated_bnchmk, a_btot_bnchmk, a_btot_exp, final_share_rate, per_capita_exp_total_py)%>%
  
  #Next I reformat the intital start time variable as a date and creating a "length of service" variable. 
  
  mutate(initial_start_date = as.Date(initial_start_date, format = "%m/%d/%Y"),
         service_length = date2016-initial_start_date,
         
  #Critically, I also add a year variable. 
  
         year = 2016) 


#Again for 2015: 
#I read in the dataset from a url of CMS's data download site. I use col_names and deliberately set the format of some of the columns. 

aco_data_2015 <- read_csv("https://data.cms.gov/api/views/7rrf-3gxr/rows.csv?accessType=DOWNLOAD",
                          col_names = TRUE,
                          cols(
                            .default = col_double(),
                            ACO_Num = col_character(),
                            ACO_Name = col_character(),
                            ACO_State = col_character(),
                            Start_Date = col_character()
                            )) %>%
  
  #I call clean_names for ease of use later.
  
  clean_names() %>%
  
  #I also select just the variables that I may use in later analysis to have a more managable dataset. 
  
  select(aco_num, aco_name, aco_state, start_date, n_ab, sav_rate, bnchmk_min_exp, gen_save_loss, earn_save_loss, qual_score, updated_bnchmk, a_btot_bnchmk, a_btot_exp, final_share_rate, per_capita_exp_total_py) %>%
  
  #Next I reformat the intital start time variable as a date and creating a "length of service" variable. 
  
  mutate(initial_start_date = as.Date(start_date, format = "%m/%d/%Y"),
         service_length = date2016-initial_start_date,
         
  #Critically, I also add a year variable. 
  
         year = 2015) %>%
  
  #For consistent format, I drop the old "start date" variable.
  
  select(-start_date)

#And lastly 2014: 
#I read in the dataset from a url of CMS's data download site. I use col_names and deliberately set the format of some of the columns. 

aco_data_2014 <- read_csv("https://data.cms.gov/api/views/888h-akbg/rows.csv?accessType=DOWNLOAD",
                          col_names = TRUE,
                          cols(
                            .default = col_double(),
                            ACO_Num = col_character(),
                            ACO_NAME = col_character(),
                            ACO_State = col_character(),
                            Start_Date = col_character(),
                            QualScore = col_double()
)) %>%
  
  #I call clean_names for ease of use later.
  
  clean_names() %>%
  
  #I also select just the variables that I may use in later analysis to have a more managable dataset. 
  
  select(aco_num, aco_name, aco_state, start_date, n_ab, sav_rate, bnchmk_min_exp, gen_save_loss, earn_save_loss, qual_score, updated_bnchmk, a_btot_bnchmk, a_btot_exp, final_share_rate, per_capita_exp_total_py) %>%
  
  #Next I reformat the intital start time variable as a date and creating a "length of service" variable. 
  
  mutate(initial_start_date = as.Date(start_date, format = "%m/%d/%Y"),
         service_length = date2015-initial_start_date,
         
  #Critically, I also add a year variable. 
  
         year = 2014)  %>%
  
  #For consistent format, I drop the old "start date" variable.
  
  select(-start_date)


```


```{r manipulation, echo = FALSE, message = FALSE, warning = FALSE, cache = TRUE}
#I begin by collapsing each of the ACO-county level datasets to the county level. 
#For now I just want the raw number of ACO beneficiaries in each county

#Starting with the 2017 data:

county_lvl_aco_2017 <- aco_county_benes_2017 %>%
  
  #I group by state and county identifiers.
  
  group_by(state_name, county_name, state_id, county_id) %>%
  
  #Then I summarize to get the total number of ACO beneficiaries and add a year variable. 
  
  summarize(aco_benes = sum(total_benes), year  = 2017) %>%
  
  #Finally I select just the variables I'll use to merging and mapping.
  
  select(state_name, county_name, aco_benes, year)


#I now apply the same process to the other years, beginning with 2016

county_lvl_aco_2016 <- aco_county_benes_2016 %>%
  
  #I group by state and county identifiers.
  
  group_by(state_name, county_name, state_id, county_id) %>%
  
  #Then I summarize to get the total number of ACO beneficiaries and add a year variable. 
  
  summarize(aco_benes = sum(total_benes), year  = 2016) %>%
  
  #Finally I select just the variables I'll use to merging and mapping.
  
  select(state_name, county_name, aco_benes, year)


#2015

county_lvl_aco_2015 <- aco_county_benes_2015 %>%
  
  #I group by state and county identifiers.
  
  group_by(state_name, county_name, state_id, county_id) %>%
  
  #Then I summarize to get the total number of ACO beneficiaries and add a year variable. 
  
  summarize(aco_benes = sum(total_benes), year  = 2015) %>%
  
  #Finally I select just the variables I'll use to merging and mapping.
  
  select(state_name, county_name, aco_benes, year)

#2014

county_lvl_aco_2014 <- aco_county_benes_2014 %>%

  #I group by state and county identifiers.
  
  group_by(state_name, county_name, state_id, county_id) %>%
  
  #Then I summarize to get the total number of ACO beneficiaries and add a year variable. 
  
  summarize(aco_benes = sum(total_benes), year  = 2014) %>%
  
  #Finally I select just the variables I'll use to merging and mapping.
  
  select(state_name, county_name, aco_benes, year)


#Here I restrict the county map shapefile to just the continental united states for the sake of better visualization.

#I start by reading in my handmade file linking the FIPS codes and state names for the continental US

state_names_codes <- read_xlsx("state_names_codes.xlsx")

#Then I make a new dataset which filters the previous one by the vector above and adds state names

continental_county_shapes <- county_map %>%

  #I mutate the statefp codes to numeric to align with the other dataset.
  
  mutate(statefp = as.numeric(statefp)) %>%
  
  #Then I filter by the codes of the continental states. 
  
  filter(statefp %in% state_names_codes$statefp) %>%
  
  #I then merge with the state names file I made to get state names too.
  
  left_join(state_names_codes, by = "statefp") %>%
  
  #I also take the opportunity to select just the variables I will need for merging or for mapping.
  
  select(state_name, name, geometry) 

#Finally I will merge all my datasets together to create the master file I can use to map. 
#First I add the shape data to each years dataset, then the county level data. 
#So I start with the 2017 county level ACO data.

temp_2017 <- county_lvl_aco_2017 %>%

  #Then I remove states not in the continental US.
  
  filter(state_name != "Alaska", state_name != "Hawaii") %>%
  
  #Then I merge with the shape information.
  
  full_join(continental_county_shapes, by = c("state_name" = "state_name", "county_name" = "name")) %>%
  
  #Then I merge with the county level medicare data.
  
  full_join(county_medicare_2017, by = c("state_name" = "state", "county_name" = "county")) %>%
  
  #Next I just select the data I want.
  
  ungroup() %>%
  select(state_name, county_name, state_and_county_fips_code, beneficiaries_with_part_a_and_part_b, ffs_beneficiaries, ma_beneficiaries, aco_benes, average_age, total_actual_costs, actual_per_capita_costs, year, geometry) %>%
  
  #Then I create MA and ACO participation rate variables. 
  
  mutate(aco_participation_rate = aco_benes/(ffs_beneficiaries+ma_beneficiaries),
         ma_participation_rate = ma_beneficiaries/(ffs_beneficiaries+ma_beneficiaries),
         log_aco_benes = log(aco_benes + 1))


#I repeat the process with the 2016 data:

temp_2016 <- county_lvl_aco_2016 %>%

    #Then I remove states not in the continental US.
  
  filter(state_name != "Alaska", state_name != "Hawaii") %>%
  
  #Then I merge with the shape information.
  
  full_join(continental_county_shapes, by = c("state_name" = "state_name", "county_name" = "name")) %>%
  
  #Then I merge with the county level medicare data.
  
  full_join(county_medicare_2017, by = c("state_name" = "state", "county_name" = "county")) %>%
  
  #Next I just select the data I want.
  
  ungroup() %>%
  select(state_name, county_name, state_and_county_fips_code, beneficiaries_with_part_a_and_part_b, ffs_beneficiaries, ma_beneficiaries, aco_benes, average_age, total_actual_costs, actual_per_capita_costs, year, geometry) %>%
  
  #Then I create MA and ACO participation rate variables. 
  
  mutate(aco_participation_rate = aco_benes/(ffs_beneficiaries+ma_beneficiaries),
         ma_participation_rate = ma_beneficiaries/(ffs_beneficiaries+ma_beneficiaries),
         log_aco_benes = log(aco_benes + 1))

#And again with 2015: 

temp_2015 <- county_lvl_aco_2015 %>%

  #Then I remove states not in the continental US.
  
  filter(state_name != "Alaska", state_name != "Hawaii") %>%
  
  #Then I merge with the shape information.
  
  full_join(continental_county_shapes, by = c("state_name" = "state_name", "county_name" = "name")) %>%
  
  #Then I merge with the county level medicare data.
  
  full_join(county_medicare_2017, by = c("state_name" = "state", "county_name" = "county")) %>%
  
  #Next I just select the data I want.
  
  ungroup() %>%
  select(state_name, county_name, state_and_county_fips_code, beneficiaries_with_part_a_and_part_b, ffs_beneficiaries, ma_beneficiaries, aco_benes, average_age, total_actual_costs, actual_per_capita_costs, year, geometry) %>%
  
  #Then I create MA and ACO participation rate variables. 
  
  mutate(aco_participation_rate = aco_benes/(ffs_beneficiaries+ma_beneficiaries),
         ma_participation_rate = ma_beneficiaries/(ffs_beneficiaries+ma_beneficiaries),
         log_aco_benes = log(aco_benes + 1))

#Finally with 2014: 

temp_2014 <- county_lvl_aco_2014 %>%
  
  #Then I remove states not in the continental US.

  filter(state_name != "Alaska", state_name != "Hawaii") %>%
  
  #Then I merge with the shape information.
  
  full_join(continental_county_shapes, by = c("state_name" = "state_name", "county_name" = "name")) %>%
  
  #Then I merge with the county level medicare data.
  
  full_join(county_medicare_2017, by = c("state_name" = "state", "county_name" = "county")) %>%
  
  #Next I just select the data I want.
  
  ungroup() %>%
  select(state_name, county_name, state_and_county_fips_code, beneficiaries_with_part_a_and_part_b, ffs_beneficiaries, ma_beneficiaries, aco_benes, average_age, total_actual_costs, actual_per_capita_costs, year, geometry) %>%
  
  #Then I create MA and ACO participation rate variables and add a logged aco_beneficiaries variable. 
  
  mutate(aco_participation_rate = aco_benes/(ffs_beneficiaries+ma_beneficiaries),
         ma_participation_rate = ma_beneficiaries/(ffs_beneficiaries+ma_beneficiaries),
         log_aco_benes = log(aco_benes + 1))

#Now I merge all of these datasets together "vertically" to create a master dataset where the unit of observation is a county year and the important data is the geometry and the number of beneficiaries. 


county_master <- rbind(temp_2017, temp_2016, temp_2015, temp_2014) %>%
  
  #I also do some cleaning to get rid of unknown counties or year.
  
  filter(county_name != "UNKNOWN") %>%
  
  #Next I replace na's with zeroes where relevant.
  
  mutate(aco_benes = replace_na(aco_benes, 0),
         ma_beneficiaries = replace_na(ma_beneficiaries, 0),
         aco_participation_rate = replace_na(aco_participation_rate, 0),
         ma_participation_rate = replace_na(ma_participation_rate, 0))


#Now I do some manipulation on the detailed ACO level datasets to accomplish two goals:
#First, generate a dummy variable for exit, entry, and stasis.
#Second, append all the years of data to create an ACO master file. 

#To generate dummies for entry and exit I use joins to get a list of which ACOs are new to a year and which are no longer present. 

#To generate variables for entry in 2014 and exit in 2017 I use datasets for 2018 and 2013 that simply have a roster of ACOs. Though this isnt enough for the analysis I want to present it is enough to determine which ACO numbers are new or disappear. 

acos_in_2018 <- read_csv("https://data.cms.gov/api/views/28n4-k8qs/rows.csv?accessType=DOWNLOAD",
                         col_names = TRUE) %>%
  clean_names() %>%
  select(aco_num)
  
acos_in_2013 <- read_csv("https://data.cms.gov/api/views/faep-t7cf/rows.csv?accessType=DOWNLOAD",
                         col_names = TRUE) %>%
  clean_names() %>%
  select(aco_num)

#To get new ACOs for year X I use anti_join with year X-1 on the left. 

new_acos_2017 <- anti_join(aco_data_2017, aco_data_2016, by = "aco_num") %>%
  
  #Then I select just the ACO number, which I'll use later.
  
  select(aco_num) %>%
  
  #I also create an indicator variable for entrance: 
  
  mutate(entered  = 1)

#Again, I perform the join. 

new_acos_2016 <- anti_join(aco_data_2016, aco_data_2015, by = "aco_num") %>%
  
  #Then I select just the ACO number, which I'll use later.
  
  select(aco_num) %>%
  
  #I also create an indicator variable for entrance: 
  
  mutate(entered  = 1)

#Again, I perform the join. 

new_acos_2015 <- anti_join(aco_data_2015, aco_data_2014, by = "aco_num") %>%
  
  #Then I select just the ACO number, which I'll use later.
  
  select(aco_num) %>%
  
  #I also create an indicator variable for entrance: 
  
  mutate(entered  = 1)

#Again, I perform the join. 

new_acos_2014 <- anti_join(aco_data_2014, acos_in_2013, by = "aco_num") %>%
  
  #Then I select just the ACO number, which I'll use later.
  
  select(aco_num) %>%
  
  #I also create an indicator variable for entrance: 
  
  mutate(entered  = 1)

#To get ACOs that exited after year X I use anti_join with year X+1 on the left. 

exit_acos_2017 <- anti_join(aco_data_2017, acos_in_2018, by = "aco_num") %>%
  
  #Then I select just the ACO number, which I'll use later.
  
  select(aco_num) %>%
  
  #I also create an indicator variable for exit: 
  
  mutate(exit = 1)

#Again, I perform the join. 

exit_acos_2016 <- anti_join(aco_data_2016, aco_data_2017, by = "aco_num") %>%
  
  #Then I select just the ACO number, which I'll use later.
  
  select(aco_num) %>%
  
  #I also create an indicator variable for exit: 

  mutate(exit = 1)

#Again, I perform the join. 

exit_acos_2015 <- anti_join(aco_data_2015, aco_data_2016, by = "aco_num") %>%
  
  #Then I select just the ACO number, which I'll use later.
  
  select(aco_num) %>%
  
  #I also create an indicator variable for exit: 
  
  mutate(exit = 1)

#Again, I perform the join. 

exit_acos_2014 <- anti_join(aco_data_2014, aco_data_2015, by = "aco_num") %>%
  
  #Then I select just the ACO number, which I'll use later.
  
  select(aco_num) %>%
  
  #I also create an indicator variable for exit: 
  
  mutate(exit = 1)


#Now with these lists of exit and entrance I mutate the datasets to add a variable for exit and entrance:

#I start with the base dataset I will mutate.

aco_temp_2017 <- aco_data_2017 %>%
  
  #Then I join the "new_acos" and "exit_acos" data for the year.
  
  left_join(new_acos_2017, by = "aco_num") %>%
  left_join(exit_acos_2017, by = "aco_num") %>%
  
  #Then I mutate to make a proper dummy variable for entrance and exit. 
  
  mutate(entered = replace_na(entered, 0),
         exit = replace_na(exit, 0)) 

#Repeating for 2016: 
#I start with the base dataset I will mutate.

aco_temp_2016 <- aco_data_2016 %>%
  
  #Then I join the "new_acos" and "exit_acos" data for the year.
  
  left_join(new_acos_2016, by = "aco_num") %>%
  left_join(exit_acos_2016, by = "aco_num") %>%
  
  #Then I mutate to make a proper dummy variable for entrance and exit. 
  
  mutate(entered = replace_na(entered, 0),
         exit = replace_na(exit, 0)) 

#Repeating again for 2015: 
#I start with the base dataset I will mutate.

aco_temp_2015 <- aco_data_2015 %>%
  
  #Then I join the "new_acos" and "exit_acos" data for the year.
  
  left_join(new_acos_2015, by = "aco_num") %>%
  left_join(exit_acos_2015, by = "aco_num") %>%
  
  #Then I mutate to make a proper dummy variable for entrance and exit. 
  
  mutate(entered = replace_na(entered, 0),
         exit = replace_na(exit, 0)) 

#And finally for 2014: 
#I start with the base dataset I will mutate.

aco_temp_2014 <- aco_data_2014 %>%
  
  #Then I join the "new_acos" and "exit_acos" data for the year.
  
  left_join(new_acos_2014, by = "aco_num") %>%
  left_join(exit_acos_2014, by = "aco_num") %>%
  
  #Then I mutate to make a proper dummy variable for entrance and exit. 
  
  mutate(entered = replace_na(entered, 0),
         exit = replace_na(exit, 0)) 


#Having added entrance and exit dummies to every year of the data I now append all my datasets to create a master file with an ACO-Year as the unit of observation. 

aco_master <- rbind(aco_temp_2017, aco_temp_2016, aco_temp_2015, aco_temp_2014)


```


```{r write, echo = FALSE}
#Here I write my master files into rds files to be used elsewhere.

write_rds(county_master, "ACO_exploration/county_master_file.rds")

write_rds(aco_master, "ACO_exploration/aco_master_file.rds")

```

  
